{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"be7d123c-c7ab-40d4-8b56-75fb9e1a5e87\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(`.${CLASS_NAME.split(' ')[0]}`);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"be7d123c-c7ab-40d4-8b56-75fb9e1a5e87\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"be7d123c-c7ab-40d4-8b56-75fb9e1a5e87\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'be7d123c-c7ab-40d4-8b56-75fb9e1a5e87' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"be7d123c-c7ab-40d4-8b56-75fb9e1a5e87\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"be7d123c-c7ab-40d4-8b56-75fb9e1a5e87\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"be7d123c-c7ab-40d4-8b56-75fb9e1a5e87\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'be7d123c-c7ab-40d4-8b56-75fb9e1a5e87' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.10.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.10.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.10.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"be7d123c-c7ab-40d4-8b56-75fb9e1a5e87\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Wiki_Hurricane_Scraper import *\n",
    "# from YouTube_Analytics import *\n",
    "from FEMA_Scraper import *\n",
    "from NOAA_Scraper import *\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from BokehPlots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDisasterInfo():\n",
    "    hurricaneDf = getHurricaneData()\n",
    "    hurricaneDf = hurricaneDf[hurricaneDf['Season'] >= 2005].set_index(\"Name\")\n",
    "    name = hurricaneDf.index.tolist()\n",
    "    season = hurricaneDf['Season'].tolist()\n",
    "    locations = getAllLocations()\n",
    "    disastersInfo = list(zip(name, season))\n",
    "    return hurricaneDf, disastersInfo, name, locations\n",
    "\n",
    "def getFundingDf(funding, disastersInfo, name, locations):\n",
    "    fundingdf = pd.DataFrame(columns=['Year'] + locations, index=name)\n",
    "    for hurricane, locs in funding.items():\n",
    "        for loc, funds in locs.items():\n",
    "            fundingdf.at[hurricane, loc] = funds\n",
    "    for name, year in disastersInfo:\n",
    "        fundingdf.at[name, 'Year'] = year \n",
    "    fundingdf.rename(index=str, columns={\"- Any -\":\"Total\"}, inplace=True)\n",
    "    return fundingdf\n",
    "\n",
    "def getYoutubeDFs(disastersinfo):\n",
    "    return getAllDisasterDfs(disastersInfo)\n",
    "\n",
    "def getNOAAFunding(kwargs):\n",
    "    return getFundingDataFromNOAA(**kwargs)\n",
    "\n",
    "def processTweetDf(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df['Total Exposure'] = df[['replies', 'retweets', 'likes']].sum(axis=1)\n",
    "    df.drop(['link', 'id', 'location'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def processYoutubeDf(file):\n",
    "    df = pd.read_csv(file, index_col=0).reset_index().drop('index', axis=1)\n",
    "    df.drop(['Favourite Count', 'Video ID'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def getCompiledDf(hurricaneNames, fundingDf, hurricaneDf, tweets_by_hurricane, youtube_by_hurricane):\n",
    "    columns = ['Tweet Count', 'Tweet Exposure', 'Hashtags', 'Video Count', 'Video Exposure',\n",
    "                   'Youtube Tags']\n",
    "    num_rows = len(tweets_by_hurricane)\n",
    "    compiledDf = pd.DataFrame(columns=columns, index=hurricaneNames)\n",
    "    compiledDf = compiledDf.merge(fundingDf[['Total','Year']], how='outer', left_index=True, right_index=True)\n",
    "    compiledDf.rename(index=str, columns={\"Total\":\"Funding\"}, inplace=True)\n",
    "    compiledDf = compiledDf.merge(hurricaneDf[['Damages']], how='outer', left_index=True, right_index=True)\n",
    "    for hurricane in hurricaneNames:\n",
    "        if hurricane in tweets_by_hurricane:\n",
    "            tweets = tweets_by_hurricane[hurricane]\n",
    "            compiledDf.loc[hurricane, 'Tweet Count'] = len(tweets)\n",
    "            compiledDf.loc[hurricane, 'Tweet Exposure'] = sum(tweets['Total Exposure'])\n",
    "            allhashes = [val.replace('\\'', '') for res in tweets['hashtags'] if res != '[]' \\\n",
    "                                                 for val in res.replace('[', '').replace(']', '').split(', ')]\n",
    "            compiledDf.loc[hurricane, 'Hashtags'] = ','.join(allhashes)\n",
    "        vids = youtube_by_hurricane[hurricane]\n",
    "        compiledDf.loc[hurricane, 'Video Count'] = len(vids)\n",
    "        compiledDf.loc[hurricane, 'Video Exposure'] = sum(vids['Views'])\n",
    "        allTags = [val.replace('\\'', '') for res in vids['Tags'] if res != '[]' \\\n",
    "                                                 for val in res.replace('[', '').replace(']', '').split(', ')]\n",
    "        compiledDf.loc[hurricane, 'Youtube Tags'] = ','.join(allTags)\n",
    "    return compiledDf\n",
    "\n",
    "def plotFunding(df, xcol, title = 'Title', xaxis='x', yaxis='y', logx=True, logy=True):\n",
    "    temp = df.reset_index()\n",
    "    temp = temp[temp['Funding']>1]\n",
    "    if logy:\n",
    "        temp['Funding'] = np.log(temp['Funding'])\n",
    "    if logx:\n",
    "        temp[xcol] = np.log(temp[xcol])\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.lmplot(x=xcol, y='Funding', data=temp, hue='Name', fit_reg=False, legend=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xaxis)\n",
    "    plt.ylabel(yaxis)\n",
    "    return\n",
    "\n",
    "    \n",
    "twitter_users_per_year = {2017: 328,\n",
    "                          2016: 319,\n",
    "                          2015: 305,\n",
    "                          2014: 288,\n",
    "                          2013: 241,\n",
    "                          2012: 185,\n",
    "                          2011: 117,\n",
    "                          2010: 54\n",
    "                            }\n",
    "\n",
    "### Specified For U.S: Data for 2014-2017 was publicly available. Data for 2005-2013 was extrapolated using a\n",
    "### quadratic fit on the found data: Formula: -0.817241 x^2 + 3300.01 x - 3.33117×10^6\n",
    "youtube_users_per_year = {2017: 180.7,\n",
    "                          2016: 176.1,\n",
    "                          2015: 170.7,\n",
    "                          2014: 163.5,\n",
    "                          2013: 151.95,\n",
    "                          2012: 140.04,\n",
    "                          2011: 128.64,\n",
    "                          2010: 114.74,\n",
    "                          2009: 99.218,\n",
    "                          2008: 82.06,\n",
    "                          2007: 63.72,\n",
    "                          2006: 42.58,\n",
    "                          2005: 20.79\n",
    "                          }\n",
    "\n",
    "\n",
    "searchParamsFema = {'source' : 'https://www.fema.gov/disasters',\n",
    "                'location' : 'Florida',\n",
    "                'incidentType' : 'Hurricane',\n",
    "                'declarationType' : 'DR',\n",
    "                'startMonth' : 'January',\n",
    "                'startYear' : 2013,\n",
    "                'endMonth' : 'December',\n",
    "                'endYear' : 2018,\n",
    "                'disasterName' : 'Irma'}\n",
    "\n",
    "searchQueryNOAA = {\n",
    "    'eventType': '(Z) Storm Surge/Tide',\n",
    "    'beginDate_mm': '01',\n",
    "    'beginDate_dd': '01',\n",
    "    'beginDate_yyyy': '2013',\n",
    "    'endDate_mm': '12',\n",
    "    'endDate_dd': '30',\n",
    "    'endDate_yyyy': '2018',\n",
    "    'county': 'ALL',\n",
    "}\n",
    "\n",
    "# funding = getAllFunding(disastersInfo, searchParamsFema)\n",
    "# np.save(\"fundingDict.npy\", funding)\n",
    "\n",
    "### Collect The Fema Funds as a CSV File\n",
    "# funding = np.load('fundingDict.npy').item()\n",
    "# df = getFundingDf(funding, disastersInfo, hurricaneNames, locations)\n",
    "# df.to_csv('fundingRaised.csv')\n",
    "\n",
    "### Collect Youtube Stats as CSV file\n",
    "# YouTubeDictDfs = getYouTubeDfs(disastersInfo)\n",
    "# for idx, (key, value) in enumerate(YouTubeDictDfs.items()):\n",
    "#     value.to_csv('YouTube Dataframes/'+key+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDataFrames():\n",
    "    ### LOAD FUNDING DATAFRAME\n",
    "    fundingDf = pd.read_csv('fundingRaised.csv', index_col=0)\n",
    "    fundingDf.drop([col for col, val in fundingDf.sum().iteritems() if val == 0], axis=1, inplace=True)\n",
    "    \n",
    "    hurricaneDf, disastersInfo, hurricaneNames, locations = getDisasterInfo()\n",
    "    \n",
    "    ### LOAD ALL TWEET DATAFRAMES\n",
    "    tweets_by_hurricane = {}\n",
    "    for file in os.listdir(\"tweet_csv\"):\n",
    "        hurricane = file.split('.')[0]\n",
    "        tweets_by_hurricane[hurricane] = processTweetDf('tweet_csv/' + file)\n",
    "\n",
    "    ### LOAD ALL YOUTUBE DATAFRAMES\n",
    "    youtube_by_hurricane = {}\n",
    "    for file in os.listdir(\"Youtube_Dataframes\"):\n",
    "        hurricane = file.split('.')[0]\n",
    "        youtube_by_hurricane[hurricane] = processYoutubeDf('Youtube_Dataframes/' + file)\n",
    "\n",
    "    ### Group Relevant Columns Together Across Df's\n",
    "    df = getCompiledDf(hurricaneNames, fundingDf, hurricaneDf, tweets_by_hurricane, youtube_by_hurricane)\n",
    "    return fundingDf, df\n",
    "\n",
    "def adjustInflation(df):\n",
    "    ### Adjusting Funding and Damages for Inflation at an average of 1.89% per year [CITE THIS]\n",
    "    inflationAdjustedDf = df.copy()\n",
    "    def calcInflation(row, col='Funding'):\n",
    "        interest = np.power(1.0186, 2018-row['Year']+1)\n",
    "        return row[col] * interest\n",
    "    inflationAdjustedDf['Funding'] = inflationAdjustedDf.apply(lambda row: calcInflation(row, col='Funding'), axis=1)\n",
    "    inflationAdjustedDf['Damages'] = inflationAdjustedDf.apply(lambda row: calcInflation(row, col='Damages'), axis=1)\n",
    "    return inflationAdjustedDf\n",
    "\n",
    "def normalizeTweetsandYouTube(df):\n",
    "    normalizedDf = df.copy()\n",
    "    normalizedTweetDf = normalizedDf[normalizedDf.Year >= 2010].copy()\n",
    "    normalizedYouTubeDf = normalizedDf.copy()\n",
    "\n",
    "    normalizedTweetDf['Tweet Exposure'] = normalizedTweetDf.apply(lambda row: \\\n",
    "                                            row['Tweet Exposure']/(twitter_users_per_year[row.Year]-twitter_users_per_year[2010]+1), axis=1)\n",
    "\n",
    "    normalizedYouTubeDf['Video Exposure'] = normalizedYouTubeDf.apply(lambda row: \\\n",
    "                                                row['Video Exposure']/(youtube_users_per_year[row.Year]*1e6), axis=1)\n",
    "    return normalizedTweetDf, normalizedYouTubeDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processTweetDf('tweet_csv/Harvey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2018-05-05\n",
       "1        2018-05-05\n",
       "2        2018-05-05\n",
       "3        2018-05-05\n",
       "4        2018-05-05\n",
       "5        2018-05-05\n",
       "6        2018-05-05\n",
       "7        2018-05-05\n",
       "8        2018-05-05\n",
       "9        2018-05-05\n",
       "10       2018-05-05\n",
       "11       2018-05-05\n",
       "12       2018-05-05\n",
       "13       2018-05-05\n",
       "14       2018-05-05\n",
       "15       2018-05-05\n",
       "16       2018-05-05\n",
       "17       2018-05-05\n",
       "18       2018-05-05\n",
       "19       2018-05-05\n",
       "20       2018-05-05\n",
       "21       2018-05-05\n",
       "22       2018-05-05\n",
       "23       2018-05-05\n",
       "24       2018-05-05\n",
       "25       2018-05-05\n",
       "26       2018-05-05\n",
       "27       2018-05-05\n",
       "28       2018-05-05\n",
       "29       2018-05-05\n",
       "            ...    \n",
       "45028    2018-01-30\n",
       "45029    2018-01-30\n",
       "45030    2018-01-30\n",
       "45031    2018-01-30\n",
       "45032    2018-01-30\n",
       "45033    2018-01-30\n",
       "45034    2018-01-30\n",
       "45035    2018-01-30\n",
       "45036    2018-01-30\n",
       "45037    2018-01-30\n",
       "45038    2018-01-30\n",
       "45039    2018-01-30\n",
       "45040    2018-01-30\n",
       "45041    2018-01-30\n",
       "45042    2018-01-30\n",
       "45043    2018-01-30\n",
       "45044    2018-01-30\n",
       "45045    2018-01-30\n",
       "45046    2018-01-30\n",
       "45047    2018-01-30\n",
       "45048    2018-01-30\n",
       "45049    2018-01-30\n",
       "45050    2018-01-30\n",
       "45051    2018-01-30\n",
       "45052    2018-01-30\n",
       "45053    2018-01-30\n",
       "45054    2018-01-30\n",
       "45055    2018-01-30\n",
       "45056    2018-01-30\n",
       "45057    2018-01-30\n",
       "Name: date, Length: 45058, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-05-05'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
