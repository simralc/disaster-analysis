{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, time, json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse as parse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Get Amount of Funding Raised/Approved for a Hurricane\n",
    "def retrieve_html(url):\n",
    "    \"\"\"\n",
    "    Return the raw HTML at the specified URL.\n",
    "\n",
    "    Args:\n",
    "        url (string): \n",
    "\n",
    "    Returns:\n",
    "        status_code (integer):\n",
    "        raw_html (string): the raw HTML content of the response, properly encoded according to the HTTP headers.\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    return (r.status_code, r.content)\n",
    "\n",
    "def getAllLocations(url):\n",
    "    code, content = retrieve_html(url)\n",
    "    if code != 200:\n",
    "        print('Could not Find Locations')\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    locationvals = soup.find('select', id=\"edit-field-dv2-state-territory-tribal-value-selective\").find_all('option')\n",
    "    return [loc.text for loc in locationvals]\n",
    "    \n",
    "    \n",
    "def getNewUrl(source, keys, params):\n",
    "    code, content = retrieve_html(source)\n",
    "    if code != 200:\n",
    "        print('Failed to Retrive Info for Hurricane ' + params['disasterName'])\n",
    "        return None\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    locationvals = soup.find('select', id=\"edit-field-dv2-state-territory-tribal-value-selective\").find(\"option\", text=params['location'])\n",
    "    incidentvals = soup.find('select', id=\"edit-field-dv2-incident-type-tid\").find(\"option\", text=params['incidentType'])\n",
    "    \n",
    "    keys['field_dv2_state_territory_tribal_value_selective'] = locationvals['value']\n",
    "    keys['field_dv2_incident_type_tid'] = incidentvals['value']\n",
    "    keys['field_dv2_incident_begin_value%5Bvalue%5D%5Bmonth%5D'] = months[params['startMonth']]\n",
    "    keys['field_dv2_incident_begin_value%5Bvalue%5D%5Byear%5D'] = params['startYear']\n",
    "    keys['field_dv2_incident_end_value%5Bvalue%5D%5Bmonth%5D'] = params['endMonth']\n",
    "    keys['field_dv2_incident_end_value%5Bvalue%5D%5Byear%5D'] = params['endYear']\n",
    "    return params['source'] + '?' + parse.urlencode(keys)\n",
    "\n",
    "def searchPageforSpending(soup, disaster):\n",
    "    b = soup.find('div', class_=\"view-content\")\n",
    "    if b == None:\n",
    "        return 0 \n",
    "    b = b.find_all('a')\n",
    "    relevantrefs = [ref for ref in b if disaster in ref.text]\n",
    "    result = 0\n",
    "    amount = re.compile(\"\\$(\\S*)\")\n",
    "    for ref in relevantrefs:\n",
    "        nexturl = 'https://www.fema.gov/' + ref['href']\n",
    "        code, content = retrieve_html(nexturl)\n",
    "        if code != 200:\n",
    "            continue\n",
    "        dissumsoup = BeautifulSoup(content, 'html.parser')\n",
    "        snaps = dissumsoup.find('div', class_=\"disaster-snapshot col-lg-4 col-md-12\").find_all('p')\n",
    "        texts = [p.text for p in snaps if '$' in p.text]\n",
    "        amounts = [amount.findall(text)[0] for text in texts]\n",
    "        values = [float(value.replace(',', '')) for value in amounts]\n",
    "        result += sum(values)\n",
    "        time.sleep(0.01)\n",
    "    return result\n",
    "\n",
    "def getRaisedFunds(params, atts):\n",
    "    nextPage = getNewUrl(params['source'], atts, params)\n",
    "    totalSpending = 0\n",
    "    while(nextPage != None):\n",
    "        time.sleep(0.2)\n",
    "        code, content = retrieve_html(nextPage)\n",
    "        if code != 200:\n",
    "            break\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        totalSpending += searchPageforSpending(soup, params['disasterName'])\n",
    "        nexttag = soup.find('a', title=\"Go to next page\")\n",
    "        if nexttag == None:\n",
    "            break                           \n",
    "        nextPage = params['source'] + '?' + nexttag['href']\n",
    "    return totalSpending\n",
    "\n",
    "def getAllFunding(disastersinfo, searchParams):\n",
    "    locations = getAllLocations(searchParams['source'])\n",
    "    fundingRaised = {}\n",
    "    for (name, year) in disastersinfo:\n",
    "        searchParams['startYear'] = year\n",
    "        searchParams['endYear'] = year\n",
    "        searchParams['disasterName'] = name\n",
    "        fundingRaised[name] = {}\n",
    "        for loc in locations:\n",
    "            searchParams['location'] = loc\n",
    "            fundingRaised[name][loc] = getRaisedFunds(searchParams, keys)\n",
    "    return fundingRaised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = {'field_dv2_state_territory_tribal_value_selective' : 'All',\n",
    "        'field_dv2_incident_type_tid' : 49124, # Hurricane Code\n",
    "        'field_dv2_declaration_type_value' : 'DR',\n",
    "        'field_dv2_incident_begin_value%5Bvalue%5D%5Bmonth%5D' : 0,\n",
    "        'field_dv2_incident_begin_value%5Bvalue%5D%5Byear%5D' : 2000,\n",
    "        'field_dv2_incident_end_value%5Bvalue%5D%5Bmonth%5D' : 0,\n",
    "        'field_dv2_incident_end_value%5Bvalue%5D%5Byear%5D' : 2000}\n",
    "months = {'January' : 1,\n",
    "          'February' : 2,\n",
    "          'March' : 3,\n",
    "          'April' : 4,\n",
    "          'May' : 5,\n",
    "          'June' : 6,\n",
    "          'July' : 7,\n",
    "          'August' : 8,\n",
    "          'September' : 9,\n",
    "          'October' : 10,\n",
    "          'November' : 11,\n",
    "          'December' : 12}\n",
    "searchParams = {'source' : 'https://www.fema.gov/disasters',\n",
    "                'location' : 'Florida',\n",
    "                'incidentType' : 'Hurricane',\n",
    "                'declarationType' : 'DR',\n",
    "                'startMonth' : 'January',\n",
    "                'startYear' : 2013,\n",
    "                'endMonth' : 'December',\n",
    "                'endYear' : 2018,\n",
    "                'disasterName' : 'Hurricane Irma'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disastersInfo = [('Irma', 2017)]\n",
    "# getAllFunding(disastersInfo, searchParams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
