{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Wiki_Hurricane_Scraper import getHurricaneData\n",
    "from FEMA_Scraper import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDisasterInfo():\n",
    "    hurricaneDf = getHurricaneData()\n",
    "    recentHurricanes = hurricaneDf[hurricaneDf['Season'] >= 2005]\n",
    "    name = recentHurricanes['Name'].tolist()\n",
    "    season = recentHurricanes['Season'].tolist()\n",
    "    locations = getAllLocations()\n",
    "    disastersInfo = list(zip(name, season))\n",
    "    return disastersInfo, name, locations\n",
    "\n",
    "def getFundingDf(funding, disastersInfo, name, locations):\n",
    "    fundingdf = pd.DataFrame(columns=['Year'] + locations, index=name)\n",
    "    for hurricane, locs in funding.items():\n",
    "        for loc, funds in locs.items():\n",
    "            fundingdf.at[hurricane, loc] = funds\n",
    "    for name, year in disastersInfo:\n",
    "        fundingdf.at[name, 'Year'] = year \n",
    "    return fundingdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disastersInfo, name, locations = getDisasterInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchParams = {'source' : 'https://www.fema.gov/disasters',\n",
    "                'location' : 'Florida',\n",
    "                'incidentType' : 'Hurricane',\n",
    "                'declarationType' : 'DR',\n",
    "                'startMonth' : 'January',\n",
    "                'startYear' : 2013,\n",
    "                'endMonth' : 'December',\n",
    "                'endYear' : 2018,\n",
    "                'disasterName' : 'Irma'}\n",
    "\n",
    "# funding = getAllFunding(disastersInfo, searchParams)\n",
    "# np.save(\"fundingDict.npy\", funding)\n",
    "\n",
    "# funding = np.load('fundingDict.npy').item()\n",
    "# df = getFundingDf(funding, disastersInfo, name, locations)\n",
    "# df.to_csv('fundingRaised.csv')\n",
    "# df = pd.read_csv('fundingRaised.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getAllDisasterDfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3ea5254e691e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mYouTubeDictDfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAllDisasterDfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisastersInfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYouTubeDictDfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'YouTube Dataframes/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getAllDisasterDfs' is not defined"
     ]
    }
   ],
   "source": [
    "# YouTubeDictDfs = getAllDisasterDfs(disastersInfo)\n",
    "# for idx, (key, value) in enumerate(YouTubeDictDfs.items()):\n",
    "#     value.to_csv('YouTube Dataframes/'+key+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katrina (358, 9)\n",
      "Harvey (502, 9)\n",
      "Maria (479, 9)\n",
      "Sandy (541, 9)\n",
      "Irma (508, 9)\n",
      "Ike (399, 9)\n",
      "Wilma (313, 9)\n",
      "Rita (287, 9)\n",
      "Matthew (509, 9)\n",
      "Irene (462, 9)\n",
      "Gustav (236, 9)\n",
      "Stan (124, 9)\n",
      "Karl (217, 9)\n",
      "Dennis (260, 9)\n",
      "Isaac (241, 9)\n",
      "Lee (148, 9)\n",
      "Dean (270, 9)\n",
      "Dolly (128, 9)\n",
      "Alex (152, 9)\n",
      "Ingrid (122, 9)\n",
      "Emily (219, 9)\n"
     ]
    }
   ],
   "source": [
    "for idx, (key, value) in enumerate(YouTubeDictDfs.items()):\n",
    "    print(key, value[value.Views > 1000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrmaDf = pd.read_csv(\"Youtube_Dataframes/Irma.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
